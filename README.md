MapReduce
=========

Project Objectives:
 - To gain working experience with Hadoop and Map Reduce
 - To understand Graph Algorithms such as PageRank
 - Running PageRank and other Algorithms that rely on Map Reduce


I wrote different algorithms using the Map Reduce technique, and ran them on different datasets. These algorithms were

  - WordCount - a simple Map Reduce algorithm that counted the total number of unique words in the dataset
  - Phrase Frequency - similar to WordCount, this algorithm found unique Phrases (of different and same size chunks).
  - Page Rank - this algorithm ranked the Wikipedia PageLink dataset in order of popularity, where popularity was decided by the number of articles that linked from one article. 

The DataSets included the Twitter MemeTracker dataset (10 GB). The dataset contained links to memes and captions for each link, as well as links that led to the meme. Word Count and Phrase Freuqency was run on the captions. 

The other Dataset was the Wikipedia PageLink dataset (27 GB). The data contains inter-article pagelinks for each article in Wikipedia. 

Project and project results by Ravish Chawla, Sourabh Bajaj, and Xialin Yan.
